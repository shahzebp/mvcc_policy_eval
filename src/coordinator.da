import sys

import queue
import uuid
import collections

import logging
import logging.handlers
import logging.config

from time import sleep
from threading import Thread
from collections import deque
from datetime import datetime
import time

from worker import Worker
from common import Request, Response, Version

class Coordinator(process):

    def setup(coordinators, database, config  ):
        
        self.logger = logging.getLogger('sLogger')

        self.exit = False
        
        self.main_cache = {}

        self.send_sequence  = 1
        self.recv_sequence  = 1

        self.session_id = uuid.uuid4()

        self.PCA = {}

        self.maxdblatency   = int(config.get("setup", "maxdblatency"))
        
        # Each coordinator intantiates its own workers
        # It is one as of now
        
        self.worker_index   = 0
        num_worker = int(config.get("setup", "num_worker_per_coord"))

        workers_set     = new(Worker, num = num_worker)
        self.workers    = list(workers_set)
        setup(self.workers, (coordinators, self.session_id, database, config))
        start(workers)

    def run():

        # Await till exit is issued by the master 
        await(received(('EXIT',)))
            
        logger.info("Exiting the Coordinators")
        # Issue await to the clients
        send(('EXIT',), to=(workers))

    def latestVersionBefore(id, attr, ts):
        version = None

        if id not in main_cache:
            main_cache[id] = {}

        if attr not in main_cache[id]:
            main_cache[id][attr] = []

        if len(main_cache[id][attr]) > 0:
            for v in reversed(main_cache[id][attr]):
                if v.wts < ts:
                    version = v
                    break
        else:
            version = Version(attr, None, 0)
            main_cache[id][attr].append(version)

        return version

    def cachedUpdates(id, curr_object, request):
        cachedResults = {}
        attrList = (request.defReadAttr[curr_object] + request.mightReadAttr[curr_object])

        for attr in attrList:
            v = latestVersionBefore(id, attr, request.timestamp)
            # if the version is not a dummy version
            if v.wts != 0:
                cachedResults[attr] = v.val
            # else no need to send such cached data. Wrker will
            # retrieve this from database

        return cachedResults

    def restart(response, id, is_prediction_correct):
        request = response.request

        for attr in request.defReadAttr[id] + request.mightReadAttr[id]:
            v = latestVersionBefore(response.request.object[id], attr, response.request.timestamp)
            v.pendingMightRead.remove(response.request.uuid)

        logger.info("[Coord {2}] Restarting request (UUID: {1}) to Coord {0} "
            .format(request.swapped, request.uuid, int(not request.swapped)))

        if (is_prediction_correct):
            coordinator_id = response.read_only_object % len(coordinators)
        else:
            coordinator_id = response.request.object[id] % len(coordinators)
        send(('FROM_RESTART', response.request, not(id)), to = (coordinators[coordinator_id]))

    def check_pca(id, request):
        attr_list = request.defReadAttr[id] + request.mightReadAttr[id]

        for attr in attr_list:
            try:
                if (PCA[request.object[id]][attr]):
                    logger.info("[Coord] Throttling request %s\n",request.uuid)
                    return False
            except KeyError:
                pass
        logger.info("[Coord] Releasing request %s\n",request.uuid)
        return True


    # Initial process when request is received.
    # This is also the point of start for restart
    def entrypoint(request):

        pca_id = request.swapped
        
        await(check_pca(pca_id, request) == True)
        
        request.timestamp   = time.time()

        # populating the pca for potential write
        # conflicting attributes
        
        if request.object[pca_id] not in PCA:
            PCA[request.object[pca_id]] = {}

        for key in request.mightWriteAttr[pca_id]:
            if key not in PCA[request.object[pca_id]]:
                PCA[request.object[pca_id]][key] = []

            PCA[request.object[pca_id]][key].append(request.uuid)

        logger.info("[Coord {0}] Sending request (UUID: {1}) to Coord {2} "
            .format(request.swapped, request.uuid, int(not request.swapped)))
        logger.debug("[Coord {0}] Sending request (seq. {1}) to Coord {2}: {3}"
            .format(request.swapped, send_sequence, int(not request.swapped), request))

        curr_object = request.swapped

        if (request.read_only):
            for attr in request.defReadAttr[curr_object]:
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.rts = request.timestamp

            for attr in request.mightReadAttr[curr_object]:
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.pendingMightRead.append(request.uuid)

        else:
            for attr in (request.defReadAttr[curr_object] + request.mightReadAttr[curr_object]):
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.pendingMightRead.append(request.uuid)
        
        request.cached_updates[curr_object] = cachedUpdates(request.object[curr_object], curr_object, request)

        # send this to next coordinator
        send_sequence =  send_sequence + 1
        
        # Need to send to appropriate coordinator
        coordinator_id = 0

        if (request.swapped == 0):
            coordinator_id = request.object[1] % len(coordinators)
        else:
            coordinator_id = request.object[0] % len(coordinators)
            
        send(('FROM_COORD_REQUEST', request), to=(coordinators[coordinator_id]))
        

    # Receive the request from the client
    def receive(msg=('FROM_CLIENT', request), from_=p):
        
        logger.info("[Coord {0}] Request received (UUID: {1}) from Client"
            .format(request.swapped, request.uuid))
        logger.debug("[Coord {0}] Request received (seq. {1}) from Client: {2}"
            .format(request.swapped, recv_sequence, request))
        
        recv_sequence = recv_sequence + 1
        
        request.owner = p
        
        entrypoint(request)
    
    def receive(msg=('FROM_RESTART', request, id), from_=p):
        
        logger.info("[Coord {0}] Request received (UUID: {1}) from Client"
            .format(request.swapped, request.uuid))
        logger.debug("[Coord {0}] Request received (seq. {1}) from Client: {2}"
            .format(request.swapped, recv_sequence, request))
        
        for attr in request.defReadAttr[id] + request.mightReadAttr[id]:
            v = latestVersionBefore(request.object[id], attr, request.timestamp)
            v.pendingMightRead.remove(request.uuid)

        recv_sequence = recv_sequence + 1
        
        entrypoint(request)

    # Receive the request from object1 coordinator
    def receive(msg=('FROM_COORD_REQUEST', request), from_=p):

        pca_id = not(request.swapped)

        '''
        await(check_pca(pca_id, request) == True)

        if request.object[pca_id] not in PCA:
            PCA[request.object[pca_id]] = {}

        for key in request.mightWriteAttr[pca_id]:
            if key not in PCA[request.object[pca_id]]:
                PCA[request.object[pca_id]][key] = []

            PCA[request.object[pca_id]][key].append(request.uuid)
        '''
        
        logger.info("[Coord {0}] Request received (UUID: {1}) from Coord {2}"
            .format(int(not request.swapped), request.uuid, request.swapped))
        logger.debug("[Coord {0}] Request received (seq. {1}) from  Coord {2}: {3}"
            .format(int(not request.swapped), recv_sequence, request.swapped, request))

        recv_sequence = recv_sequence + 1

        curr_object = 1

        if (request.swapped == 1):
            curr_object = 0

        if (request.read_only):
            for attr in request.defReadAttr[curr_object]:
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.rts = request.timestamp

            for attr in request.mightReadAttr[curr_object]:
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.pendingMightRead.append(request.uuid)


        else:
            for attr in (request.defReadAttr[curr_object] + request.mightReadAttr[curr_object]):
                v = latestVersionBefore(request.object[curr_object], attr, request.timestamp)
                v.pendingMightRead.append(request.uuid)

        request.cached_updates[curr_object] = cachedUpdates(request.object[curr_object], curr_object, request)

        logger.info("[Coord {0}] Sending request (UUID: {1}) to Worker"
            .format(int(not request.swapped), request.uuid))
        logger.debug("[Coord {0}] Sending request (seq. {1}) to Worker: {2}"
            .format(int(not request.swapped), send_sequence, request))

        send_sequence =  send_sequence + 1

        send(('FROM_COORD', request), to = (workers[worker_index]))

        # Round robin worker usage for fair share distribution
        worker_index = worker_index + 1

        if worker_index == len(workers):
            worker_index = 0

    # object1 cooridinator receives response from the worker
    # This response is the evaluation result for the request
    # There exists a compostion of request inside response
    def receive(msg=('FROM_WORKER_READATTR', response, i, is_prediction_correct), from_=p):

        logger.info("[Coord] Response received (UUID. {0}) from {1}"
            .format(response.request.uuid, p))
        logger.debug("[Coord] Response received (seq. {0}) from {1}: {2}"
            .format(recv_sequence, p, response))
        recv_sequence = recv_sequence + 1


        for attr in response.request.mightReadAttr[i]:
            v = latestVersionBefore(response.request.object[i], attr, response.request.timestamp)
            v.pendingMightRead.remove(response.request.uuid)

            if attr in response.readAttr[i]:
                v.rts = response.request.timestamp

        if (is_prediction_correct == True and response.request.read_only == False):
            for key in response.request.mightWriteAttr[i]:
                PCA[response.request.object[i]][key].remove(response.request.uuid)

    def check_conflicts(response):
        updated_object = response.updated_object
        
        for key in response.updates:
            v = latestVersionBefore(updated_object, key, response.request.timestamp)
            
            if v.rts > response.request.timestamp:                
                logger.error("Conflict detected for request %s\n",response.request.uuid)
                return True
        
        return False

    def update_cache(response):
        updated_object = response.updated_object
        
        for key,val in response.updates.items():
            version = Version(key, val, response.request.timestamp)

            if updated_object not in main_cache:
                main_cache[updated_object] = {}

            if key not in main_cache[updated_object]:
                main_cache[updated_object][key] = []

            main_cache[updated_object][key].append(version)

    def check_PMR_empty(response):
        updated_object = response.updated_object

        for key in response.updates:
            v = latestVersionBefore(updated_object, key, response.request.timestamp)
            len_pmr = len(v.pendingMightRead)

            if len_pmr > 1:
                return False

            if (len_pmr == 1) and (v.pendingMightRead[0] != response.request.uuid):
                return False

        # return true when all the attr have pmr empty
        return True

    # object1 cooridinator receives response from the worker
    # This response is the evaluation result for the request
    # There exists a compostion of request inside response
    def receive(msg=('FROM_WORKER_RESPONSE', response, sessionID), from_=p):

        #TODO check session id. if not equal then return
        logger.info("[Coord] Coorindator Session ID. {0} and Worker Session ID: {1}".format(self.session_id, sessionID))
        logger.info("[Coord] Response received (UUID. {0}) from Worker"
            .format(response.request.uuid))
        logger.debug("[Coord] Response received (seq. {0}) from Worker: {1}"
            .format(recv_sequence, response))
        
        recv_sequence = recv_sequence + 1
        
        is_prediction_correct = True
        
        if(self.session_id != sessionID):
            is_prediction_correct = False

        updated_object_index = 0

        if (response.updated_object == -1):
            updated_object_index = not(response.request.swapped)
            response.updated_object = response.request.object[updated_object_index]

        else:
            if (response.request.object[1] == response.updated_object):
                updated_object_index = 1

        conflict = check_conflicts(response)

        if conflict == False:
            await(check_PMR_empty(response) == True)

            i_conflict = check_conflicts(response)
            
            if i_conflict == False:
                    
                send(('FROM_COORDINATOR_ATTR_UPDATE', response.updated_object,
                    response.updates, response.request.timestamp), to = (database))
                
                update_cache(response)
                
                attr_list = (response.request.defReadAttr[updated_object_index] +
                            response.request.mightReadAttr[updated_object_index])

                for attr in attr_list:
                    v = latestVersionBefore(response.request.object[updated_object_index], attr, response.request.timestamp)
                    v.pendingMightRead.remove(response.request.uuid)

                    if attr in response.readAttr[updated_object_index]:
                        v.rts = response.request.timestamp

                send(('OUTCOME', response), to = (response.request.client))
                if (is_prediction_correct == False):
                    for key in response.request.mightWriteAttr[updated_object_index]:
                        PCA[response.request.object[updated_object_index]][key].remove(response.request.uuid)

                coordinator_id = response.read_only_object % len(coordinators)    
                send(('FROM_WORKER_READATTR', response, not(updated_object_index), is_prediction_correct), to = (coordinators[coordinator_id]))

                #for key in response.mightWriteAttr[0]:
                #   PCA[response.updated_object][key].remove(response.request.uuid)
            else:
                #for key in response.mightWriteAttr:
                #    PCA[response.updated_object][key].remove(response.request.uuid)

                logger.error("[Coord] Inner conflict detected for {0}"
                    .format(response.request.uuid))

                restart(response, (updated_object_index), is_prediction_correct)

            
        else:

            logger.error("[Coord] Outer conflict detected for {0}"
                .format(response.request.uuid))

            restart(response, (updated_object_index), is_prediction_correct)